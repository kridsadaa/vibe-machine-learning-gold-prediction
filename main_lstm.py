import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import tensorflow as tf
import warnings
warnings.filterwarnings('ignore')

# Try to import optional packages with error handling
try:
    import seaborn as sns
    plt.style.use('seaborn-v0_8')
    sns.set_palette("husl")
    HAS_SEABORN = True
    print("âœ… Seaborn loaded successfully")
except ImportError:
    HAS_SEABORN = False
    plt.style.use('default')
    print("âš ï¸ Seaborn not found - using matplotlib default style")

try:
    from ta.trend import EMAIndicator
    from ta.momentum import RSIIndicator
    HAS_TA = True
    print("âœ… TA library loaded successfully")
except ImportError:
    HAS_TA = False
    print("âŒ TA library not found. Please install: pip install ta")
    exit(1)

print("\nğŸ† Gold Price Prediction with LSTM")
print("=" * 50)

# 1. à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
print("ğŸ“¥ à¸à¸³à¸¥à¸±à¸‡à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸²à¸„à¸²à¸—à¸­à¸‡...")
try:
    df = yf.download("GC=F", start="2020-01-01", end="2024-12-31")[['Close']]
    print(f"âœ… à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¹€à¸£à¹‡à¸ˆ: {len(df)} à¸§à¸±à¸™")
    print(f"ğŸ“Š à¸Šà¹ˆà¸§à¸‡à¸£à¸²à¸„à¸²: ${df['Close'].min():.2f} - ${df['Close'].max():.2f}")
except Exception as e:
    print(f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥: {e}")
    exit(1)

# 2. à¸„à¸³à¸™à¸§à¸“ Technical Indicators
print("ğŸ” à¸à¸³à¸¥à¸±à¸‡à¸„à¸³à¸™à¸§à¸“ Technical Indicators...")
df['EMA20'] = EMAIndicator(df['Close'], window=20).ema_indicator()
df['RSI'] = RSIIndicator(df['Close'], window=14).rsi()

# à¹€à¸à¸´à¹ˆà¸¡ technical indicators à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡
df['SMA10'] = df['Close'].rolling(window=10).mean()
df['Price_Change'] = df['Close'].pct_change()
df['Volatility'] = df['Price_Change'].rolling(window=10).std()

df.dropna(inplace=True)
print(f"âœ… à¸„à¸³à¸™à¸§à¸“ Technical Indicators à¸ªà¸³à¹€à¸£à¹‡à¸ˆ")

# 3. à¸ªà¸£à¹‰à¸²à¸‡ Target: à¸£à¸²à¸„à¸²à¸§à¸±à¸™à¸–à¸±à¸”à¹„à¸›à¸¡à¸²à¸à¸à¸§à¹ˆà¸²à¸§à¸±à¸™à¸™à¸µà¹‰ = 1 (à¸‚à¸¶à¹‰à¸™), à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ = 0
df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)
df.dropna(inplace=True)

print(f"ğŸ“Š Target Distribution:")
up_days = (df['Target'] == 1).sum()
down_days = (df['Target'] == 0).sum()
print(f"   ğŸ“ˆ à¸‚à¸¶à¹‰à¸™ (1): {up_days} à¸§à¸±à¸™ ({(df['Target'] == 1).mean():.1%})")
print(f"   ğŸ“‰ à¸¥à¸‡ (0): {down_days} à¸§à¸±à¸™ ({(df['Target'] == 0).mean():.1%})")

# 4. à¸ªà¸£à¹‰à¸²à¸‡ Sequence Data (window = 10 à¸§à¸±à¸™)
def create_sequences(data, target, window=10):
    X, y = [], []
    for i in range(len(data) - window):
        X.append(data[i:i+window])
        y.append(target[i+window])
    return np.array(X), np.array(y)

# à¹ƒà¸Šà¹‰ features à¸¡à¸²à¸à¸‚à¸¶à¹‰à¸™
features = ['Close', 'EMA20', 'RSI', 'SMA10', 'Price_Change', 'Volatility']
print(f"ğŸ”„ à¹ƒà¸Šà¹‰ Features: {features}")

scaler = MinMaxScaler()
scaled = scaler.fit_transform(df[features])

print("ğŸ”„ à¸à¸³à¸¥à¸±à¸‡à¸ªà¸£à¹‰à¸²à¸‡ Sequence Data...")
X, y = create_sequences(scaled, df['Target'].values, window=10)
print(f"âœ… à¸ªà¸£à¹‰à¸²à¸‡ Sequences à¸ªà¸³à¹€à¸£à¹‡à¸ˆ: {X.shape[0]} sequences, {X.shape[1]} timesteps, {X.shape[2]} features")

# 5. à¹à¸šà¹ˆà¸‡ Train/Test
split = int(len(X) * 0.8)
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

print(f"ğŸ“Š Data Split:")
print(f"   ğŸ”§ Training: {len(X_train)} sequences")
print(f"   ğŸ§ª Testing: {len(X_test)} sequences")

# 6. à¸ªà¸£à¹‰à¸²à¸‡ LSTM model
print("ğŸ§  à¸à¸³à¸¥à¸±à¸‡à¸ªà¸£à¹‰à¸²à¸‡ LSTM Model...")
model = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.LSTM(32, return_sequences=False),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# à¹€à¸à¸´à¹ˆà¸¡ learning rate scheduler
initial_learning_rate = 0.001
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate,
    decay_steps=100,
    decay_rate=0.96,
    staircase=True)

model.compile(
    loss='binary_crossentropy', 
    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),
    metrics=['accuracy']
)

print("ğŸ“‹ Model Architecture:")
model.summary()

# 7. à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥
print("\nğŸš€ à¸à¸³à¸¥à¸±à¸‡à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥...")

# à¸ªà¸£à¹‰à¸²à¸‡ callbacks
callbacks = [
    tf.keras.callbacks.EarlyStopping(
        patience=15, 
        restore_best_weights=True, 
        verbose=1,
        monitor='val_loss'
    ),
    tf.keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=7,
        min_lr=1e-7,
        verbose=1
    )
]

# à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥
try:
    history = model.fit(
        X_train, y_train, 
        epochs=100, 
        batch_size=32, 
        validation_split=0.15, 
        callbacks=callbacks, 
        verbose=1
    )
    print("âœ… à¸à¸²à¸£à¹€à¸—à¸£à¸™à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ")
except Exception as e:
    print(f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹€à¸—à¸£à¸™: {e}")
    exit(1)

# 8. à¸—à¸”à¸ªà¸­à¸šà¹à¸¥à¸°à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸œà¸¥
print("\nğŸ§ª à¸à¸³à¸¥à¸±à¸‡à¸—à¸”à¸ªà¸­à¸šà¹‚à¸¡à¹€à¸”à¸¥...")
y_pred = model.predict(X_test, verbose=0).flatten()
y_pred_class = (y_pred > 0.5).astype(int)

# à¸„à¸³à¸™à¸§à¸“ metrics
acc = accuracy_score(y_test, y_pred_class)
print(f"\nğŸ“Š à¸œà¸¥à¸à¸²à¸£à¸›à¸£à¸°à¹€à¸¡à¸´à¸™:")
print(f"   ğŸ¯ Accuracy: {acc:.2%}")

# Additional metrics
from sklearn.metrics import precision_score, recall_score, f1_score

precision = precision_score(y_test, y_pred_class)
recall = recall_score(y_test, y_pred_class)
f1 = f1_score(y_test, y_pred_class)

print(f"   ğŸ“ˆ Precision: {precision:.2%}")
print(f"   ğŸ“‰ Recall: {recall:.2%}")
print(f"   ğŸ¯ F1-Score: {f1:.2%}")

# Classification Report
print(f"\nğŸ“ˆ Classification Report:")
print(classification_report(y_test, y_pred_class, target_names=['à¸¥à¸‡', 'à¸‚à¸¶à¹‰à¸™']))

# 9. Visualization
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# Plot 1: Training History
axes[0,0].plot(history.history['loss'], label='Training Loss', linewidth=2)
axes[0,0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)
axes[0,0].set_title('ğŸ“ˆ Model Loss During Training')
axes[0,0].set_xlabel('Epoch')
axes[0,0].set_ylabel('Loss')
axes[0,0].legend()
axes[0,0].grid(True, alpha=0.3)

# Plot 2: Accuracy History
axes[0,1].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)
axes[0,1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)
axes[0,1].set_title('ğŸ¯ Model Accuracy During Training')
axes[0,1].set_xlabel('Epoch')
axes[0,1].set_ylabel('Accuracy')
axes[0,1].legend()
axes[0,1].grid(True, alpha=0.3)

# Plot 3: Confusion Matrix
cm = confusion_matrix(y_test, y_pred_class)
if HAS_SEABORN:
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['Predicted à¸¥à¸‡', 'Predicted à¸‚à¸¶à¹‰à¸™'],
                yticklabels=['Actual à¸¥à¸‡', 'Actual à¸‚à¸¶à¹‰à¸™'],
                ax=axes[1,0])
else:
    im = axes[1,0].imshow(cm, interpolation='nearest', cmap='Blues')
    axes[1,0].figure.colorbar(im, ax=axes[1,0])
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            axes[1,0].text(j, i, format(cm[i, j], 'd'),
                         ha="center", va="center",
                         color="white" if cm[i, j] > thresh else "black")
    axes[1,0].set_xticks([0, 1])
    axes[1,0].set_yticks([0, 1])
    axes[1,0].set_xticklabels(['Predicted à¸¥à¸‡', 'Predicted à¸‚à¸¶à¹‰à¸™'])
    axes[1,0].set_yticklabels(['Actual à¸¥à¸‡', 'Actual à¸‚à¸¶à¹‰à¸™'])
axes[1,0].set_title('ğŸ” Confusion Matrix')

# Plot 4: Prediction Probability Distribution
axes[1,1].hist(y_pred, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
axes[1,1].set_title('ğŸ“Š Prediction Probability Distribution')
axes[1,1].set_xlabel('Predicted Probability')
axes[1,1].set_ylabel('Frequency')
axes[1,1].axvline(x=0.5, color='red', linestyle='--', linewidth=2, label='Threshold')
axes[1,1].legend()
axes[1,1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# 10. à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸§à¸±à¸™à¸¥à¹ˆà¸²à¸ªà¸¸à¸”
print(f"\nğŸ”® à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ:")
latest_seq = X[-1:]
pred_prob = model.predict(latest_seq, verbose=0)[0][0]
pred_direction = "ğŸ“ˆ à¸‚à¸¶à¹‰à¸™" if pred_prob > 0.5 else "ğŸ“‰ à¸¥à¸‡"

print(f"   ğŸ’ à¸£à¸²à¸„à¸²à¸—à¸­à¸‡à¸¥à¹ˆà¸²à¸ªà¸¸à¸”: ${df['Close'].iloc[-1]:.2f}")
print(f"   ğŸ¯ à¸„à¸§à¸²à¸¡à¸™à¹ˆà¸²à¸ˆà¸°à¹€à¸›à¹‡à¸™à¸£à¸²à¸„à¸² 'à¸‚à¸¶à¹‰à¸™' à¸à¸£à¸¸à¹ˆà¸‡à¸™à¸µà¹‰: {pred_prob*100:.2f}%")
print(f"   ğŸ“Š à¸—à¸´à¸¨à¸—à¸²à¸‡à¸—à¸µà¹ˆà¸„à¸²à¸”à¸à¸²à¸£à¸“à¹Œ: {pred_direction}")
print(f"   ğŸ”¥ à¸„à¸§à¸²à¸¡à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆ: {abs(pred_prob - 0.5) * 200:.1f}%")

# 11. Feature Importance Analysis (à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡)
print(f"\nğŸ“‹ à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡:")
print(f"   ğŸ“Š RSI à¸¥à¹ˆà¸²à¸ªà¸¸à¸”: {df['RSI'].iloc[-1]:.1f}")
print(f"   ğŸ“ˆ EMA20 à¸¥à¹ˆà¸²à¸ªà¸¸à¸”: ${df['EMA20'].iloc[-1]:.2f}")
print(f"   ğŸ“ˆ SMA10 à¸¥à¹ˆà¸²à¸ªà¸¸à¸”: ${df['SMA10'].iloc[-1]:.2f}")
print(f"   âš–ï¸ à¸£à¸²à¸„à¸² vs EMA20: {'Above' if df['Close'].iloc[-1] > df['EMA20'].iloc[-1] else 'Below'}")
print(f"   ğŸ“Š Volatility à¸¥à¹ˆà¸²à¸ªà¸¸à¸”: {df['Volatility'].iloc[-1]:.4f}")
print(f"   ğŸ“ˆ Price Change à¸¥à¹ˆà¸²à¸ªà¸¸à¸”: {df['Price_Change'].iloc[-1]:.4f}")

# 12. Model Performance Summary
print(f"\nğŸ“ˆ à¸ªà¸£à¸¸à¸›à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¹‚à¸¡à¹€à¸”à¸¥:")
print(f"   ğŸ¯ Test Accuracy: {acc:.2%}")
print(f"   ğŸ“Š à¸—à¸³à¸™à¸²à¸¢à¸–à¸¹à¸: {(y_pred_class == y_test).sum()} / {len(y_test)}")
print(f"   ğŸ“ˆ True Positives: {((y_pred_class == 1) & (y_test == 1)).sum()}")
print(f"   ğŸ“‰ True Negatives: {((y_pred_class == 0) & (y_test == 0)).sum()}")

# 13. à¸šà¸±à¸™à¸—à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥ (optional)
try:
    model_save = input("\nğŸ’¾ à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸šà¸±à¸™à¸—à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ? (y/n): ")
    if model_save.lower() in ['y', 'yes']:
        model.save('gold_lstm_model.h5')
        # à¸šà¸±à¸™à¸—à¸¶à¸ scaler à¸”à¹‰à¸§à¸¢
        import joblib
        joblib.dump(scaler, 'gold_scaler.pkl')
        print("âœ… à¸šà¸±à¸™à¸—à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥à¹à¸¥à¸° scaler à¹€à¸£à¸µà¸¢à¸šà¸£à¹‰à¸­à¸¢à¹à¸¥à¹‰à¸§:")
        print("   ğŸ“ gold_lstm_model.h5")
        print("   ğŸ“ gold_scaler.pkl")
except:
    print("âš ï¸ à¸‚à¹‰à¸²à¸¡à¸à¸²à¸£à¸šà¸±à¸™à¸—à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥")

print(f"\nğŸ‰ à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™!")
print("=" * 50)

# 14. à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¸šà¸±à¸™à¸—à¸¶à¸à¹„à¸§à¹‰ (à¸„à¸³à¹à¸™à¸°à¸™à¸³)
print(f"\nğŸ’¡ à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¸šà¸±à¸™à¸—à¸¶à¸à¹„à¸§à¹‰:")
print("""
# à¹‚à¸«à¸¥à¸”à¹‚à¸¡à¹€à¸”à¸¥à¹à¸¥à¸° scaler
import tensorflow as tf
import joblib

model = tf.keras.models.load_model('gold_lstm_model.h5')
scaler = joblib.load('gold_scaler.pkl')

# à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸—à¸³à¸™à¸²à¸¢
# predictions = model.predict(new_data)
""")