import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import tensorflow as tf
import warnings
warnings.filterwarnings('ignore')

# Try to import optional packages with error handling
try:
    import seaborn as sns
    plt.style.use('seaborn-v0_8')
    sns.set_palette("husl")
    HAS_SEABORN = True
except ImportError:
    HAS_SEABORN = False
    plt.style.use('default')

try:
    from ta.trend import EMAIndicator
    from ta.momentum import RSIIndicator
    HAS_TA = True
except ImportError:
    HAS_TA = False
    print("âŒ TA library not found. Please install: pip install ta")
    exit(1)

print("ğŸ† Gold Price Prediction with LSTM (Robust Version)")
print("=" * 50)

# 1. à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ (Robust method)
print("ğŸ“¥ à¸à¸³à¸¥à¸±à¸‡à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸£à¸²à¸„à¸²à¸—à¸­à¸‡...")
try:
    # Method 1: Try standard download
    try:
        ticker = yf.Ticker("GC=F")
        df = ticker.history(start="2020-01-01", end="2024-12-31")
        df = df[['Close']].copy()
        df.columns = ['Close']
        
        if df.empty or len(df) < 100:
            raise ValueError("Insufficient data")
            
        print(f"âœ… à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¹€à¸£à¹‡à¸ˆ (Method 1): {len(df)} à¸§à¸±à¸™")
        
    except:
        # Method 2: Fallback with different parameters
        print("âš ï¸ à¸¥à¸­à¸‡à¸§à¸´à¸˜à¸µà¸­à¸·à¹ˆà¸™...")
        df = yf.download("GC=F", start="2020-01-01", end="2024-12-31", progress=False)
        df = df[['Close']].copy()
        df.columns = ['Close']
        
        if df.empty:
            raise ValueError("No data downloaded")
            
        print(f"âœ… à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¹€à¸£à¹‡à¸ˆ (Method 2): {len(df)} à¸§à¸±à¸™")
    
    # à¹à¸ªà¸”à¸‡à¸ªà¸–à¸´à¸•à¸´à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
    current_price = float(df['Close'].iloc[-1])
    min_price = float(df['Close'].min())
    max_price = float(df['Close'].max())
    
    print(f"ğŸ’° à¸£à¸²à¸„à¸²à¸¥à¹ˆà¸²à¸ªà¸¸à¸”: ${current_price:.2f}")
    print(f"ğŸ“Š à¸Šà¹ˆà¸§à¸‡à¸£à¸²à¸„à¸²: ${min_price:.2f} - ${max_price:.2f}")
    
except Exception as e:
    print(f"âŒ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸”à¹‰: {e}")
    print("ğŸ’¡ à¸à¸£à¸¸à¸“à¸²à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸­à¸´à¸™à¹€à¸—à¸­à¸£à¹Œà¹€à¸™à¹‡à¸•")
    exit(1)

# 2. à¸„à¸³à¸™à¸§à¸“ Technical Indicators
print("ğŸ” à¸à¸³à¸¥à¸±à¸‡à¸„à¸³à¸™à¸§à¸“ Technical Indicators...")
try:
    df['EMA20'] = EMAIndicator(df['Close'], window=20).ema_indicator()
    df['RSI'] = RSIIndicator(df['Close'], window=14).rsi()
    
    # à¹€à¸à¸´à¹ˆà¸¡ indicators à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡
    df['SMA10'] = df['Close'].rolling(window=10).mean()
    df['Price_Change'] = df['Close'].pct_change()
    df['Volatility'] = df['Price_Change'].rolling(window=10).std()
    
    # à¸¥à¸š NaN values
    df.dropna(inplace=True)
    
    if len(df) < 50:
        raise ValueError("Insufficient data after cleaning")
    
    print(f"âœ… à¸„à¸³à¸™à¸§à¸“ Technical Indicators à¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
    print(f"ğŸ“Š à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸”: {len(df)} à¸§à¸±à¸™")

except Exception as e:
    print(f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“ indicators: {e}")
    exit(1)

# 3. à¸ªà¸£à¹‰à¸²à¸‡ Target
print("ğŸ¯ à¸à¸³à¸¥à¸±à¸‡à¸ªà¸£à¹‰à¸²à¸‡ Target...")
df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)
df.dropna(inplace=True)

up_days = int((df['Target'] == 1).sum())
down_days = int((df['Target'] == 0).sum())
up_pct = up_days / len(df) * 100
down_pct = down_days / len(df) * 100

print(f"ğŸ“Š Target Distribution:")
print(f"   ğŸ“ˆ à¸‚à¸¶à¹‰à¸™ (1): {up_days} à¸§à¸±à¸™ ({up_pct:.1f}%)")
print(f"   ğŸ“‰ à¸¥à¸‡ (0): {down_days} à¸§à¸±à¸™ ({down_pct:.1f}%)")

# 4. à¸ªà¸£à¹‰à¸²à¸‡ Sequence Data
print("ğŸ”„ à¸à¸³à¸¥à¸±à¸‡à¸ªà¸£à¹‰à¸²à¸‡ Sequence Data...")

def create_sequences(data, target, window=10):
    X, y = [], []
    for i in range(len(data) - window):
        X.append(data[i:i+window])
        y.append(target[i+window])
    return np.array(X), np.array(y)

features = ['Close', 'EMA20', 'RSI', 'SMA10', 'Price_Change', 'Volatility']
print(f"ğŸ“‹ à¹ƒà¸Šà¹‰ Features: {features}")

# Scale features
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df[features])

# à¸ªà¸£à¹‰à¸²à¸‡ sequences
X, y = create_sequences(scaled_data, df['Target'].values, window=10)
print(f"âœ… à¸ªà¸£à¹‰à¸²à¸‡ Sequences à¸ªà¸³à¹€à¸£à¹‡à¸ˆ: {X.shape}")

# 5. à¹à¸šà¹ˆà¸‡ Train/Test
split_idx = int(len(X) * 0.8)
X_train, X_test = X[:split_idx], X[split_idx:]
y_train, y_test = y[:split_idx], y[split_idx:]

print(f"ğŸ“Š Data Split:")
print(f"   ğŸ”§ Training: {len(X_train)} sequences")
print(f"   ğŸ§ª Testing: {len(X_test)} sequences")

# 6. à¸ªà¸£à¹‰à¸²à¸‡ LSTM Model
print("ğŸ§  à¸à¸³à¸¥à¸±à¸‡à¸ªà¸£à¹‰à¸²à¸‡ LSTM Model...")

model = tf.keras.Sequential([
    tf.keras.layers.LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.LSTM(32, return_sequences=False),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(
    loss='binary_crossentropy',
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=['accuracy']
)

print("ğŸ“‹ Model Summary:")
model.summary()

# 7. à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥
print("\nğŸš€ à¸à¸³à¸¥à¸±à¸‡à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥...")

callbacks = [
    tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True, verbose=1),
    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, verbose=1)
]

try:
    history = model.fit(
        X_train, y_train,
        epochs=100,
        batch_size=32,
        validation_split=0.15,
        callbacks=callbacks,
        verbose=1
    )
    print("âœ… à¸à¸²à¸£à¹€à¸—à¸£à¸™à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ")
except Exception as e:
    print(f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸à¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¹€à¸—à¸£à¸™: {e}")
    exit(1)

# 8. à¸—à¸”à¸ªà¸­à¸šà¹‚à¸¡à¹€à¸”à¸¥
print("\nğŸ§ª à¸à¸³à¸¥à¸±à¸‡à¸—à¸”à¸ªà¸­à¸šà¹‚à¸¡à¹€à¸”à¸¥...")
y_pred = model.predict(X_test, verbose=0).flatten()
y_pred_class = (y_pred > 0.5).astype(int)

# à¸„à¸³à¸™à¸§à¸“ metrics
acc = accuracy_score(y_test, y_pred_class)
print(f"\nğŸ“Š à¸œà¸¥à¸à¸²à¸£à¸›à¸£à¸°à¹€à¸¡à¸´à¸™:")
print(f"   ğŸ¯ Accuracy: {acc:.2%}")

# 9. Visualization
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# Training Loss
axes[0,0].plot(history.history['loss'], 'b-', label='Training Loss', linewidth=2)
axes[0,0].plot(history.history['val_loss'], 'r-', label='Validation Loss', linewidth=2)
axes[0,0].set_title('ğŸ“ˆ Model Loss')
axes[0,0].legend()
axes[0,0].grid(True, alpha=0.3)

# Training Accuracy
axes[0,1].plot(history.history['accuracy'], 'b-', label='Training Accuracy', linewidth=2)
axes[0,1].plot(history.history['val_accuracy'], 'r-', label='Validation Accuracy', linewidth=2)
axes[0,1].set_title('ğŸ¯ Model Accuracy')
axes[0,1].legend()
axes[0,1].grid(True, alpha=0.3)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_class)
if HAS_SEABORN:
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1,0])
else:
    im = axes[1,0].imshow(cm, cmap='Blues')
    for i in range(2):
        for j in range(2):
            axes[1,0].text(j, i, str(cm[i, j]), ha='center', va='center')

axes[1,0].set_title('ğŸ” Confusion Matrix')
axes[1,0].set_xlabel('Predicted')
axes[1,0].set_ylabel('Actual')

# Prediction Distribution
axes[1,1].hist(y_pred, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
axes[1,1].axvline(x=0.5, color='red', linestyle='--', linewidth=2)
axes[1,1].set_title('ğŸ“Š Prediction Distribution')
axes[1,1].set_xlabel('Predicted Probability')

plt.tight_layout()
plt.show()

# 10. à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ
print(f"\nğŸ”® à¸à¸²à¸£à¸à¸¢à¸²à¸à¸£à¸“à¹Œ:")
latest_seq = X[-1:]
pred_prob = float(model.predict(latest_seq, verbose=0)[0][0])
pred_direction = "ğŸ“ˆ à¸‚à¸¶à¹‰à¸™" if pred_prob > 0.5 else "ğŸ“‰ à¸¥à¸‡"

# à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¥à¹ˆà¸²à¸ªà¸¸à¸” (safe conversion)
current_price = float(df['Close'].iloc[-1])
ema20_current = float(df['EMA20'].iloc[-1])
rsi_current = float(df['RSI'].iloc[-1])
volatility_current = float(df['Volatility'].iloc[-1])

print(f"   ğŸ’ à¸£à¸²à¸„à¸²à¸—à¸­à¸‡à¸¥à¹ˆà¸²à¸ªà¸¸à¸”: ${current_price:.2f}")
print(f"   ğŸ¯ à¸„à¸§à¸²à¸¡à¸™à¹ˆà¸²à¸ˆà¸°à¹€à¸›à¹‡à¸™à¸£à¸²à¸„à¸² 'à¸‚à¸¶à¹‰à¸™' à¸à¸£à¸¸à¹ˆà¸‡à¸™à¸µà¹‰: {pred_prob*100:.2f}%")
print(f"   ğŸ“Š à¸—à¸´à¸¨à¸—à¸²à¸‡à¸—à¸µà¹ˆà¸„à¸²à¸”à¸à¸²à¸£à¸“à¹Œ: {pred_direction}")
print(f"   ğŸ”¥ à¸„à¸§à¸²à¸¡à¸¡à¸±à¹ˆà¸™à¹ƒà¸ˆ: {abs(pred_prob - 0.5) * 200:.1f}%")

print(f"\nğŸ“‹ à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡:")
print(f"   ğŸ“Š RSI à¸¥à¹ˆà¸²à¸ªà¸¸à¸”: {rsi_current:.1f}")
print(f"   ğŸ“ˆ EMA20 à¸¥à¹ˆà¸²à¸ªà¸¸à¸”: ${ema20_current:.2f}")
print(f"   âš–ï¸ à¸£à¸²à¸„à¸² vs EMA20: {'Above' if current_price > ema20_current else 'Below'}")
print(f"   ğŸ“Š Volatility à¸¥à¹ˆà¸²à¸ªà¸¸à¸”: {volatility_current:.4f}")

# 11. à¸ªà¸£à¸¸à¸›à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸
correct_predictions = int((y_pred_class == y_test).sum())
total_predictions = len(y_test)

print(f"\nğŸ“ˆ à¸ªà¸£à¸¸à¸›à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¹‚à¸¡à¹€à¸”à¸¥:")
print(f"   ğŸ¯ à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³: {acc:.2%}")
print(f"   âœ… à¸—à¸³à¸™à¸²à¸¢à¸–à¸¹à¸: {correct_predictions}/{total_predictions}")
print(f"   ğŸ“Š à¸ˆà¸³à¸™à¸§à¸™ epochs à¸—à¸µà¹ˆà¹€à¸—à¸£à¸™: {len(history.history['loss'])}")

print(f"\nğŸ‰ à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™!")
print("=" * 50)